{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cd4b20-d55b-4a98-aaaf-5cb21cf09f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    "# Date; 2. . 2022 - 2. . 2022\n",
    "# Title: Korean_NER\n",
    "# Professor: Seung-Hoon Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98df6f6-cbfe-41bc-88fb-829834b90249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d75b32-3eb3-4ec9-9628-8dc8814d2586",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ae779c2310ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset_NER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mner_collate_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodeling_ner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBert_NER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtag_id_converter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTag_ID_Converter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "from DataPreprocessing import Data_NER, ner_collate_fn\n",
    "from modeling_ner import Bert_NER\n",
    "from tag_id_converter import Tag_ID_Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c5933-32b5-40e5-a3c2-233c89f2e726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d3b709-febb-4ebe-8eac-5852a887f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a12bf3-7745-4de2-a44b-edbf46b7f2fa",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b6e865-968d-4e76-a18e-3eac832a8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_dir = 'C:\\\\Users\\\\LG\\\\Desktop\\\\github\\\\JBNU-2022-SPRING\\\\English world class tagging & Korean_Named Entity Recognition\\\\Ko_En_NER_POStag_data\\Ko_NER_POS'\n",
    "PATH_ko_train = os.path.join(PATH_dir, 'prepro_train.json')\n",
    "PATH_ko_test = os.path.join(PATH_dir, 'prepro_test.json')\n",
    "PATH_ko_dev = os.path.join(PATH_dir, 'prepro_dev.json')\n",
    "\n",
    "PATH_tag_cnt_dict = os.path.join(PATH_dir, 'prepro_tag_cnt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676b379-eedc-4d5b-8b7f-6c60183d9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset_NER(PATH_ko_train)\n",
    "dataset_test = Dataset_NER(PATH_ko_test)\n",
    "dataset_dev = Dataset_NER(PATH_ko_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a353666-e805-4818-8361-8d9ddfc18ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_converter = Tag_ID_Converter(PATH_tag_cnt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112652e-ac9d-4c17-b3f0-cfb31324658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train', len(dataset_train))\n",
    "print('test', len(dataset_test))\n",
    "print('dev', len(dataset_dev))\n",
    "tag_converter.id_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932509f-7d91-43f4-ba54-5785f496c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "partial_collate_fn = partial(ner_collate_fn, tokenizer, tag_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95e478-6ddd-4512-84f8-036ed62b35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=partial_collate_fn\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial_collate_fn\n",
    ")\n",
    "dataloader_dev = DataLoader(\n",
    "    dataset_dev,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f62ca1-ab23-4861-b3ab-7d36a59fca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_num = len(tag_converter.tag_to_id)\n",
    "model = Bert_NER(tag_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc5c0e-b048-44bd-ad93-408f2d940e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELoss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = AdamW(model.parameters(), lr=1.0e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262c91b-d4c2-48d8-8eb7-b07d71349b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda(6)\n",
    "# device = model.bert.device\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464a17d-1538-4293-9abd-ac0cbdfdd738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(train_epoch):\n",
    "    model.train()\n",
    "\n",
    "    for iteration, batch in enumerate(dataloader_train):\n",
    "        batch_inputs = {k: v.cuda(device) for k, v in list(batch[0].items())}\n",
    "        batch_labels = batch[1].cuda(device)\n",
    "\n",
    "        output = model(**batch_inputs)\n",
    "        loss = CELoss(output.view(-1, output.size(-1)), batch_labels.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (iteration + 1) % 10 == 0:\n",
    "            print(f'{iteration:3} - loss: {loss.item()}')\n",
    "\n",
    "    # todo 매 에포크가 끝나면 dev 데이터로 성능 비교하기\n",
    "    # Early Stopping 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5fd54-23d8-453a-87b0-abc73950b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "gold_list = []\n",
    "pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for iteration, batch in enumerate(dataloader_test):\n",
    "        batch_inputs = {k: v.cuda(device) for k, v in list(batch[0].items())}\n",
    "        batch_labels = batch[1].cuda(device)\n",
    "        \n",
    "        output = model(**batch_inputs)\n",
    "        loss = CELoss(output.view(-1, output.size(-1)), batch_labels.view(-1))\n",
    "        \n",
    "        print('loss:', loss.item())\n",
    "        pred_ids = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        for g, p in zip(batch_labels, pred_ids):\n",
    "            gold_mask = g != tag_converter.pad_id\n",
    "            \n",
    "            gold = tag_converter.convert_ids_to_tags(g[gold_mask].tolist())\n",
    "            pred = tag_converter.convert_ids_to_tags(p[gold_mask].tolist())\n",
    "            gold_list.append(gold)\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "            print(gold)\n",
    "            print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e813451-0100-4f9b-b49e-fc2bba9226fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_list_flat = []\n",
    "pred_list_flat = []\n",
    "for g, p in zip(gold_list, pred_list):\n",
    "    gold_list_flat += g\n",
    "    pred_list_flat += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedac99-b5f2-416e-9cb0-1cc98f132a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gold_list_flat, pred_list_flat, digits=5, labels=list(tag_converter.tag_to_id.keys())[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ee831-e9bc-455b-9903-75d1eddc9c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562b268-317e-4f85-a475-51b4c846de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_type(tag_name):\n",
    "    tag_class = tag_name.split('-')[0]\n",
    "    tag_type = tag_name.split('-')[-1]\n",
    "    return tag_class, tag_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d5aad-a27e-4ee3-8434-d2f8a6e9caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(seq):\n",
    "    default = \"O\"\n",
    "\n",
    "    chunks = []\n",
    "    chunk_type, chunk_start = None, None\n",
    "    for i, tok in enumerate(seq):\n",
    "        # End of a chunk 1\n",
    "        if tok == default and chunk_type is not None:\n",
    "            # Add a chunk.\n",
    "            chunk = (chunk_type, chunk_start, i)\n",
    "            chunks.append(chunk)\n",
    "            chunk_type, chunk_start = None, None\n",
    "\n",
    "        # End of a chunk + start of a chunk!\n",
    "        elif tok != default:\n",
    "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok)\n",
    "            if chunk_type is None:\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
    "                chunk = (chunk_type, chunk_start, i)\n",
    "                chunks.append(chunk)\n",
    "                chunk_type, chunk_start = tok_chunk_type, i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # end condition\n",
    "    if chunk_type is not None:\n",
    "        chunk = (chunk_type, chunk_start, len(seq))\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b792c1-846f-478b-99cb-46453328357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ner_F1(total_answers, total_preds):\n",
    "    num_match = num_preds = num_answers = 0\n",
    "\n",
    "    for answers, preds in zip(total_answers, total_preds):\n",
    "\n",
    "        answer_seg_result = set(get_chunks(answers))\n",
    "        pred_seg_result = set(get_chunks(preds))\n",
    "\n",
    "        num_match += len(answer_seg_result & pred_seg_result)\n",
    "        num_answers += len(answer_seg_result)\n",
    "        num_preds += len(pred_seg_result)\n",
    "\n",
    "    precision = 100.0 * num_match / num_preds\n",
    "    recall = 100.0 * num_match / num_answers\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return precision, recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24c8e9-95b7-4b35-8f63-5859b2dd8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_ner_F1(gold_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ace50-8cc1-48d3-91f2-a0f47fdc96f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
