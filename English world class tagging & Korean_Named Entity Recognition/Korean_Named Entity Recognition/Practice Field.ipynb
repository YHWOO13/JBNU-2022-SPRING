{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e06bf649-83cd-4252-a7b7-890d02376c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertModel, FlaubertModel\n",
    "# from transformers import BertModel\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ecc02de-c4ce-483e-9ba9-f8c67d1d20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETAINED_MODEL_NAME)\n",
    "# bert = BertModel.from_pretrained(PRETAINED_MODEL_NAME)\n",
    "# flaubert = FlaubertModel.from_pretrained(language_model_dir, output_loading_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4f836f-9103-4207-a3f7-e1e39cc1c1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[2,1],[1,3]]\n",
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "441e06c5-c49e-45b3-8606-946339e2da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    [['나의 우상은 박지성'],\n",
    "     ['o','o','o','p']],\n",
    "    [['박지성은 영원한 13번이자 7번'],\n",
    "     ['o','o','o','p','o','o','o','p']],\n",
    "    [[],\n",
    "     []]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7393df3-89ae-48b6-9fce-6b30ab6f7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박지성은 영원한 13번이자 7번']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6e616c-987f-4431-90ba-060a9a833ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def sum(a, b):\n",
    "    \n",
    "    return print(a, b)\n",
    "\n",
    "f = partial(sum, 10, 2)   \n",
    "f\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8964fa6a-7d96-49b5-bedc-3bc2c8932b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22a0a1c-a085-4e7f-b3f7-d562b598030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10a1ff-246d-4d8a-886e-1a2c5ca81c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['rr','rrr','rrrr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71221dd6-e28e-4b89-b037-5c0f5b05dfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216528a3-b01f-4a65-a451-673d4f7ae619",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict(가=1, 나=2, 다=3, 라=4, 마=5, 바=6, 사=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f3ee01-9b7f-495f-9d22-1161e0bc34e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가': 1, '나': 2, '다': 3, '라': 4, '마': 5, '바': 6, '사': 7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c824e306-24e5-454c-9403-419a1b702c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a0e175-c785-4147-83f9-2f2ea3ec63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['가', '다', '다', '사']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92bf9e47-4e59-4728-81b3-63e413568ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PAD', '가', '다', '다', '사', 'PAD']]\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "\n",
    "c.append(['PAD'] + b + ['PAD'])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada1a818-a100-40b3-867b-17d4bb0a18f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74a177dd-7aa1-436b-8686-fa8541801fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-82f312509aa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "b = a.get(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e93c9a-92a8-4089-aa1c-0cdc23af5a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6f002-315e-4303-a767-8da5047627b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_to_id ={'[PAD]': 0, 'B-<휠': 1, 'B-OG': 2, 'I-조선': 3, 'I-PS': 4, 'B-LC': 5, 'B-1': 6, 'I-<휠': 7, 'I-LC': 8, 'B-PS': 9, 'I-TI': 10, \n",
    "            'B-목소': 11, 'O': 12, 'I-목소': 13, 'I-1': 14, 'I-': 15, 'B-조선': 16, 'I-OG': 17, 'B-': 18, 'I-DT': 19, 'B-TI': 20, 'B-DT': 21}\n",
    "\n",
    "convert_to = []\n",
    "def make_same_len(batch):\n",
    "    \n",
    "    each_len_list = [len(sample) for sample in batch]\n",
    "    max_len = max(each_len_list)\n",
    "    \n",
    "    padded_batch = []\n",
    "    pad_id = 0\n",
    "    special_token = 0    \n",
    "\n",
    "    for sample in batch:\n",
    "        padded_batch.append([special_token] + sample+ [pad_id] * (max_len - len(sample)) + [special_token])\n",
    "   \n",
    "    for j in padded_batch:\n",
    "        j = tag_to_id.get(j)\n",
    "        convert_to.append(j)\n",
    "    padded_batch = convert_to\n",
    "    return padded_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13d7a912-1cff-411f-9e88-755f332382cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to = []\n",
    "def make_same_len(batch):\n",
    "    each_len_list = [len(sample) for sample in batch]\n",
    "    max_len = max(each_len_list)\n",
    "    \n",
    "    padded_batch = []\n",
    "    pad_id = 0\n",
    "    special_token = 'PAD'\n",
    "\n",
    "    for sample in batch:\n",
    "        padded_batch.append(['PAD'] + sample+ ['PAD'] * (max_len - len(sample)) + ['PAD'])\n",
    "    \n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "193ed0fb-c3bf-4a6d-8c48-544ab5f62a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_fn_custom(data):\n",
    "    \n",
    "    input_sent = [sample[0] for sample in data]\n",
    "    labels = [sample[2] for sample in data]\n",
    "\n",
    "    batch_inputs = tokenizer(input_sent, padding = True, return_tensors = \"pt\")\n",
    "    batch_labels = make_same_len(labels)\n",
    "#     batch_labels = torch.tensor(batch_labels)\n",
    "    \n",
    "    return batch_inputs, batch_labels\n",
    "#     return {'input': padded_inputs.contiguous(),\n",
    "#             'label': torch.stack(labels).contiguous()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49948ccf-bb30-4e49-a00b-7b645dbf5cc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b8349fa91135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# partial_collate_fn = collate_fn_custom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpartial_collate_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mner_fn_custom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m '''\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "# partial (func, /, *args, **keywords)  positional argument: args, keyword argument: keywords\n",
    "\n",
    "# partial_collate_fn = partial(collate_fn_custom, tokenizer, tag_converter)\n",
    "# partial_collate_fn = collate_fn_custom\n",
    "\n",
    "partial_collate_fn = partial(ner_fn_custom, tokenizer)\n",
    "\n",
    "'''\n",
    "partial_collate_fn = partial(collate_fn_custom, tokenizer, tag_converter)\n",
    "'''\n",
    "# ner_collate_fn: padding & making batch?\n",
    "'''\n",
    "def ner_collate_fn(tokenizer, tag_converter):\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db4a3edd-6f0a-4b73-ad5b-b536411c8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[1],[2,2],[3,3,3],[4,4,4,4],[5,5,5,5,5],[6,6,6,6,6,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4ac005f-bc44-4603-9938-0b644c434691",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    b,\n",
    "    batch_size = 3,\n",
    "    shuffle = True,\n",
    "    collate_fn = make_same_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10866d58-7cf4-45e0-953b-c1e52a8efcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PAD', 1, 'PAD', 'PAD', 'PAD'], ['PAD', 3, 3, 3, 'PAD'], ['PAD', 2, 2, 'PAD', 'PAD']]\n",
      "[['PAD', 5, 5, 5, 5, 5, 'PAD', 'PAD'], ['PAD', 4, 4, 4, 4, 'PAD', 'PAD', 'PAD'], ['PAD', 6, 6, 6, 6, 6, 6, 'PAD']]\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader_train:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7d251-fd0b-4218-913c-832be7ff1ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
