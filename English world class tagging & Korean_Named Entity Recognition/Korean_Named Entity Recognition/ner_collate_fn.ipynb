{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86d1ea9-c832-40c9-87e5-703d43c198d5",
   "metadata": {},
   "source": [
    "# Author: Yoonhyuck WOO / JBNU_Industrial Information system Engineering\n",
    "# Date; 2. 22. 2022 - 2. . 2022\n",
    "# Title: Korean_NER\n",
    "# Professor: Seung-Hoon Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e514007-9a31-45ab-8794-c563a1242ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c979a59a-ee54-43b4-890a-c25a6f9609d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_len_data_list(min_len, max_len, num_data):\n",
    "    random_data = []\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        sample_len = random.randrange(min_len, max_len)\n",
    "        sample = [random.randint(0, 9) for ii in range(sample_len)]\n",
    "        random_data.append(sample)\n",
    "    \n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4746e9a6-0a7f-403f-988d-cd090c3007d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 7, 5, 1, 5, 2, 6, 3, 6, 0, 6, 1, 3, 8, 2, 2, 9, 6],\n",
       " [5, 9, 8, 2, 9, 4, 1, 3, 5, 9, 8, 1, 9, 6, 4, 1, 3],\n",
       " [2, 2, 9, 4, 5, 2, 8, 1, 7, 5, 0, 8],\n",
       " [4, 2, 1, 0, 2, 2, 8, 9, 5, 3, 9],\n",
       " [2, 1, 7, 5, 9, 2, 5, 7, 9, 7, 4, 0, 3, 5, 3, 9],\n",
       " [8, 4, 0, 7, 1, 2, 9, 3, 9, 4, 5, 6, 9, 5, 6, 7, 7],\n",
       " [9, 1, 6, 7, 4, 4, 4, 1, 0, 4, 7, 2, 5],\n",
       " [5, 9, 3, 3, 6, 8, 5, 4, 2, 9, 2, 7],\n",
       " [7, 9, 7, 9, 5, 6, 6, 9, 7, 8, 8, 9, 0, 0, 1, 1, 4, 6],\n",
       " [2, 2, 2, 9, 5, 4, 6, 3, 1, 0, 0, 9, 0, 7, 4, 6, 4]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_random_len_data_list(10, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b05fe-1065-465b-9321-435cc9541040",
   "metadata": {},
   "source": [
    "# __getitem__\n",
    " - If slicing is performed in the list while helping to implement slicing, it is important that the '__getitem__ ' method is executed internally. Therefore, the __getitem__ method is essential to slice on an object.\n",
    " - In order to implement slicing through the object itself without direct access to the instance variable, the **getitem special method must be defined.** And this function must receive the index as an argument.\n",
    " \n",
    " # __len__\n",
    "- By defining a __len_() function in the class, an instance of the class may be transferred to the __len_() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5fee535-2839-464f-8465-149b17f1636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_custom(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9d258-5e7c-44e8-ae48-45a60189e3c0",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1511b45c-96e4-4a53-8e9a-4d20e3181443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_same_len(batch):\n",
    "    \n",
    "    each_len_list = [len(sample) for sample in batch]\n",
    "    print('each_len_list', each_len_list)\n",
    "    \n",
    "    max_len = max(each_len_list)\n",
    "    \n",
    "    padded_batch = []\n",
    "    pad_id = 0\n",
    "    \n",
    "    for sample in batch:\n",
    "        padded_batch.append([13] + sample + [pad_id] * (max_len - len(sample)) + [13])\n",
    "#         padded_batch.insert(-1,13)\n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85291096-1097-4e80-a4f6-f29dd6bc422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each_len_list [3, 10, 10, 2, 6]\n",
      "rand\n",
      "[[6, 9, 4], [2, 0, 8, 0, 2, 6, 4, 2, 7, 4], [0, 9, 7, 5, 9, 3, 5, 7, 6, 2], [1, 9], [5, 8, 3, 3, 6, 1]]\n",
      "example\n",
      "[[13, 6, 9, 4, 0, 0, 0, 0, 0, 0, 0, 13], [13, 2, 0, 8, 0, 2, 6, 4, 2, 7, 4, 13], [13, 0, 9, 7, 5, 9, 3, 5, 7, 6, 2, 13], [13, 1, 9, 0, 0, 0, 0, 0, 0, 0, 0, 13], [13, 5, 8, 3, 3, 6, 1, 0, 0, 0, 0, 13]]\n"
     ]
    }
   ],
   "source": [
    "rand = make_random_len_data_list(2, 11, 5) # (min_len, max_len, num_data)\n",
    "example = make_same_len(rand)\n",
    "\n",
    "print('rand')\n",
    "print(rand)\n",
    "print('example')\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308055f-1f6f-4887-827b-74490dabc11c",
   "metadata": {},
   "source": [
    "- Attention_mask : 1 where you care and 0 where you don't care. 1: actual word 0: non-ac\n",
    " - Input_ids : the IDs of the sentence morpheme.\n",
    " - Token_type_ids : for the question problem, but it's enough to set it to zero now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4559d0c7-166f-4c7e-bdc1-bac5d032edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_custom_2(input_ids, attention_mask): # => (tokenizer, tag_converter,token_type_ids) \n",
    "                                                          # token_type_ids: 0으로 설정 지금은 필요 x => 전처리 데이터 (batch)\n",
    "    \n",
    "    \n",
    "    padded_batch = make_same_len(batch)\n",
    "    \n",
    "    padded_batch = torch.tensor(padded_batch)\n",
    "    \n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff9d33fc-9aea-43e4-ad9e-2ae58191c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_custom_3(data):\n",
    "    inputs = [sample[0] for sample in data]\n",
    "    labels = [sample[2] for sample in data]\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first = True)\n",
    "    \n",
    "    return {'input': padded_inputs.contiguous(),\n",
    "            'label': torch.stack(labels).contiguous()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67d78f-569c-4e87-a864-534e385e7525",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1200f6b-b35f-4bae-ba2b-5fd0a352f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_custom(batch):\n",
    "    \n",
    "    padded_batch = make_same_len(batch)\n",
    "    \n",
    "    padded_batch = torch.tensor(padded_batch)\n",
    "    \n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba2b38fa-60cd-4d1b-8335-0fa827b2eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = make_random_len_data_list(10, 20, 10)\n",
    "ds = Dataset_custom(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dc53216-4d48-4966-b9e7-5a6557dfcb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[6, 9, 9, 0, 2, 9, 3, 6, 1, 6, 0, 3, 7, 7, 2, 9],\n",
       " [1, 6, 3, 6, 1, 8, 0, 1, 8, 9, 0, 3, 5, 2, 1, 8, 5, 7, 1],\n",
       " [4, 8, 9, 8, 0, 0, 7, 8, 3, 8, 4, 7, 0, 7, 3, 1, 5, 4, 7]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ds))\n",
    "ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a261936-6746-4a00-b657-4d084b4595e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each_len_list [16, 19, 19]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-6b5d82021c17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcollate_fn_custom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-f52610406310>\u001b[0m in \u001b[0;36mcollate_fn_custom\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpadded_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_same_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpadded_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type list)"
     ]
    }
   ],
   "source": [
    "collate_fn_custom(ds[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af796981-d0d4-43f2-8704-a1edb89c6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader (\n",
    "    ds,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn_custom\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "703933d8-f37b-43ad-b80c-e9893ff5f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each_len_list [15, 19]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-8e7768dc8626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-f52610406310>\u001b[0m in \u001b[0;36mcollate_fn_custom\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpadded_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_same_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpadded_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type list)"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dl):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6738f2-62f3-4dad-b553-98738c1e138a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b78798-48f1-4dc1-8be9-717f270b2aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e2df3-bd4f-4abd-a0b8-b0670111bf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
