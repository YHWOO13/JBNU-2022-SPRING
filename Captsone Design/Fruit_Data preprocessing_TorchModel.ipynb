{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ebe222-ee74-424c-afe2-0c4566c496fd",
   "metadata": {},
   "source": [
    "# MNIST 데이터 설명\n",
    "- https://sdc-james.gitbook.io/onebook/4.-and/5.1./5.1.3.-mnist-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89590d6-6067-4471-851e-d06410a4dca0",
   "metadata": {},
   "source": [
    "# 이미지 픽셀화 및 CNN학습\n",
    "- https://rdmkyg.blogspot.com/2021/06/cnn-cat-and-dog-dataset.html\n",
    "- https://wikidocs.net/61073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace76cf3-1bbd-4a0b-9d76-b01a26f2c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d30645c-80b1-46e5-9c16-28886fc3bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa563d0-7ba1-48c6-a652-6b0b5b0dedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding: 60개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e286c487-4e8e-40e9-b240-aeb6c6d67025",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_PATH_dir = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터'\n",
    "label_PATH_dir = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d223c196-c1ab-4ce6-ad0d-c300e80a0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = glob.glob(image_PATH_dir+'\\\\*.png')\n",
    "label_data = glob.glob(label_PATH_dir+'\\\\*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42831f99-1dda-4fc1-a809-4a916ddb718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-11_1TOP.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-12_2FR45.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-13_3FR90.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-14_4DI45.png']\n",
      "['D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-11_1TOP.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-12_2FR45.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-13_3FR90.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-14_4DI45.json']\n"
     ]
    }
   ],
   "source": [
    "print(image_data[1:5])\n",
    "print(label_data[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773ba1d-8202-4e58-b9d3-b0544e6c6374",
   "metadata": {},
   "source": [
    "# labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e265ba5-0291-4b8f-a1af-bd0440ad2173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese-cabbage_M_1-4_4DI45\n",
      "['chinese-cabbage', 'M', '1-4', '4DI45']\n",
      "chinese-cabbage_M\n"
     ]
    }
   ],
   "source": [
    "labelling = []\n",
    "\n",
    "# a = image_data[0]\n",
    "a = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\chinese-cabbage_M_1-4_4DI45'\n",
    "a = a.split('\\\\')[4]\n",
    "print(a)\n",
    "\n",
    "a = a.split('_')\n",
    "print(a)\n",
    "\n",
    "a = a[0] + '_' + a[1] \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2232708f-a75b-44e5-b021-512fa720e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = []\n",
    "for i in label_data:\n",
    "    label = i\n",
    "    label = label.split('\\\\')[4]\n",
    "    label = label.split('_')\n",
    "    if label[0] == 'chinese-cabbage':\n",
    "        label = label[0] + '_' + label[1]\n",
    "        labelling.append(label)\n",
    "    else:\n",
    "        label = label[0] + '_' + label[1] + '_' + label[2]\n",
    "        labelling.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fe9868-b904-4219-802a-aeef544b7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380\n",
      "['apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L']\n"
     ]
    }
   ],
   "source": [
    "k = sorted(labelling)\n",
    "print(len(k))\n",
    "print(k[0:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7515e657-507d-4211-a7f8-a459cb385d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_fuji_L', 'apple_fuji_M', 'apple_fuji_S', 'apple_yanggwang_L', 'apple_yanggwang_M', 'apple_yanggwang_S', 'cabbage_green_L', 'cabbage_green_M', 'cabbage_green_S', 'cabbage_red_L', 'cabbage_red_M', 'cabbage_red_S', 'chinese-cabbage_L', 'chinese-cabbage_M', 'chinese-cabbage_S', 'garlic_uiseong_L', 'garlic_uiseong_M', 'garlic_uiseong_S', 'mandarin_hallabong_L', 'mandarine_hallabong_M', 'mandarine_hallabong_S', 'mandarine_onjumilgam_L', 'mandarine_onjumilgam_M', 'mandarine_onjumilgam_S', 'onion_red_L', 'onion_red_M', 'onion_red_S', 'onion_white_L', 'onion_white_M', 'onion_white_S', 'pear_chuhwang_L', 'pear_chuhwang_M', 'pear_chuhwang_S', 'pear_singo_L', 'pear_singo_M', 'pear_singo_S', 'persimmon_bansi_L', 'persimmon_bansi_M', 'persimmon_bansi_S', 'persimmon_booyu_L', 'persimmon_booyu_M', 'persimmon_booyu_S', 'persimmon_daebong_L', 'persimmon_daebong_M', 'persimmon_daebong_S', 'potato_seolbong_L', 'potato_seolbong_M', 'potato_seolbong_S', 'potato_sumi_L', 'potato_sumi_M', 'potato_sumi_S', 'radish_winter-radish_L', 'radish_winter-radish_S', 'radish_winter-radish_m']\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "l = sorted(set(labelling))\n",
    "print(l)\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2f5042-2352-4ab6-a12c-44901baf96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = np.array(labelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b10820-83a6-4df6-97ac-3da47bcbf647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'fuji', 'l']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "text_to_word_sequence(labelling[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d51348-164a-4c6b-81a9-110df962b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973679d2-728c-44db-9e5f-dce5001b4314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53}\n",
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(2380, 54)\n"
     ]
    }
   ],
   "source": [
    "# 레이블 인코딩\n",
    "items = labelling\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labelling = encoder.transform(items)\n",
    "\n",
    "\n",
    "# 원핫 인코딩\n",
    "labels = encoder.inverse_transform(labelling)\n",
    "labels = labels.reshape(-1,1)\n",
    "o_h_encoder = OneHotEncoder()\n",
    "o_h_encoder.fit(labels)\n",
    "o_h_labels = o_h_encoder.transform(labels)\n",
    "\n",
    "print(set(labelling))\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(o_h_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(o_h_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07b9960-76e7-4345-857d-9d1e43f07fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(o_h_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d64466-b1e2-4257-aaf2-3a629e6386ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "arr = o_h_labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e57ad2-36e4-4def-b32d-0a808aeadefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 54)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e9750e-2fff-42b0-9423-366bb9be986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = torch.tensor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "635e9f97-5ae6-4a7e-b277-e73b0db831d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f70474a-7957-49a2-88c5-ddeb9d095b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54])\n"
     ]
    }
   ],
   "source": [
    "print(arr[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "663796d7-f877-4798-ba32-ded8cbd8f51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380\n"
     ]
    }
   ],
   "source": [
    "print(len(labelling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac9619-8245-47c8-863a-fd41ce5e7524",
   "metadata": {},
   "source": [
    "# Transferring Image_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce52d83b-2639-4e6e-802c-3696444af283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pilimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b6cea1-6ebd-4b1c-83d4-639e8764ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for j in image_data:\n",
    "    # Read image \n",
    "\n",
    "    image1 = Image.open(j)\n",
    "    imag1_size = image1.size\n",
    "    \n",
    "    # Resize image\n",
    "    image1 = image1.resize((int(imag1_size[0]*(0.064)), int(imag1_size[1]*(0.064))))\n",
    "    imag1_size = image1.size\n",
    "    \n",
    "    # Fetch image pixel data to numpy array\n",
    "    pix = np.array(image1)\n",
    "    pix = pix / 255\n",
    "    pix = pix.flatten()\n",
    "\n",
    "    image.append(pix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c593c3-b55c-43a8-a714-f0d75bdd6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c228535e-3d02-42a4-9f6f-c07137be2703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0.78431373 0.85490196 0.8627451  ... 0.78431373 0.83921569 0.84705882]\n"
     ]
    }
   ],
   "source": [
    "print(type(image))\n",
    "print(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac59d7-2990-44ea-aebf-8f83bbafbadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdac8c06-503f-471e-b7fc-1d738dd4d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "788fdbf1-56da-4a49-afdf-caed2bc4c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 12288)\n",
      "(2380,)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "print(labelling.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "360e24d2-d7cc-4949-a3ee-fc96b92bb5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image, labelling, test_size = 1/7, random_state = 0)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# like zipping\n",
    "ds_train = TensorDataset(X_train, y_train) # container that binds learning data X and label Y. (only tensor type)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size = 10, shuffle = True)\n",
    "loader_test = DataLoader(ds_test, batch_size = 10, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01910ab-c336-47fc-ac98-6a2b3ba0e85d",
   "metadata": {},
   "source": [
    "# Model (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cffa6a5d-41ff-44b6-ba9f-740eeab149cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(64*64*3, 200))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2',nn.Linear(200,100))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc4', nn.Linear(100,54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6ac76aac-1d81-4302-b760-af0c9dc40746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef18cb9-df9b-4add-9f77-2d51414bc8a3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "62063747-9ee0-45ce-8005-d81bbeafd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch{}: 완료\\n\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2e446-047b-456b-9df0-5aa160c47af5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ceb430a9-8ac7-425e-bcc0-2aad6aa7639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader_test:\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "            \n",
    "            \n",
    "    data_num = len(loader_test.dataset)\n",
    "    print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100 * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a6ecd9a7-f2e5-4930-ad91-c29e5d7edc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 데이터에서 예측 정확도: 11/340 (3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9cf76-d0e5-416d-a33b-96af8eeeebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1: 완료\n",
      "\n",
      "epoch11: 완료\n",
      "\n",
      "epoch21: 완료\n",
      "\n",
      "epoch31: 완료\n",
      "\n",
      "epoch41: 완료\n",
      "\n",
      "epoch51: 완료\n",
      "\n",
      "epoch61: 완료\n",
      "\n",
      "epoch71: 완료\n",
      "\n",
      "epoch81: 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    train(epoch)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a357aeb-194b-488c-bfb2-0eda989b3e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
