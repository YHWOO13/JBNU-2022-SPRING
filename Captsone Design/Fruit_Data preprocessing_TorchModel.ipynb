{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ebe222-ee74-424c-afe2-0c4566c496fd",
   "metadata": {},
   "source": [
    "# MNIST 데이터 설명\n",
    "- https://sdc-james.gitbook.io/onebook/4.-and/5.1./5.1.3.-mnist-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89590d6-6067-4471-851e-d06410a4dca0",
   "metadata": {},
   "source": [
    "# 이미지 픽셀화 및 CNN학습\n",
    "- https://rdmkyg.blogspot.com/2021/06/cnn-cat-and-dog-dataset.html\n",
    "- https://wikidocs.net/61073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace76cf3-1bbd-4a0b-9d76-b01a26f2c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d30645c-80b1-46e5-9c16-28886fc3bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa563d0-7ba1-48c6-a652-6b0b5b0dedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding: 60개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e286c487-4e8e-40e9-b240-aeb6c6d67025",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_PATH_dir = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터'\n",
    "label_PATH_dir = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d223c196-c1ab-4ce6-ad0d-c300e80a0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = glob.glob(image_PATH_dir+'\\\\*.png')\n",
    "label_data = glob.glob(label_PATH_dir+'\\\\*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42831f99-1dda-4fc1-a809-4a916ddb718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-11_1TOP.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-12_2FR45.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-13_3FR90.png', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\원천데이터\\\\apple_fuji_L_1-14_4DI45.png']\n",
      "['D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-11_1TOP.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-12_2FR45.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-13_3FR90.json', 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\apple_fuji_L_1-14_4DI45.json']\n"
     ]
    }
   ],
   "source": [
    "print(image_data[1:5])\n",
    "print(label_data[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773ba1d-8202-4e58-b9d3-b0544e6c6374",
   "metadata": {},
   "source": [
    "# labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e265ba5-0291-4b8f-a1af-bd0440ad2173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese-cabbage_M_1-4_4DI45\n",
      "['chinese-cabbage', 'M', '1-4', '4DI45']\n",
      "chinese-cabbage_M\n"
     ]
    }
   ],
   "source": [
    "labelling = []\n",
    "\n",
    "# a = image_data[0]\n",
    "a = 'D:\\\\DOWNLOAD\\\\2020-02-068.농산물품질_sample\\\\라벨링 데이터\\\\chinese-cabbage_M_1-4_4DI45'\n",
    "a = a.split('\\\\')[4]\n",
    "print(a)\n",
    "\n",
    "a = a.split('_')\n",
    "print(a)\n",
    "\n",
    "a = a[0] + '_' + a[1] \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2232708f-a75b-44e5-b021-512fa720e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = []\n",
    "for i in label_data:\n",
    "    label = i\n",
    "    label = label.split('\\\\')[4]\n",
    "    label = label.split('_')\n",
    "    if label[0] == 'chinese-cabbage':\n",
    "        label = label[0] + '_' + label[1]\n",
    "        labelling.append(label)\n",
    "    else:\n",
    "        label = label[0] + '_' + label[1] + '_' + label[2]\n",
    "        labelling.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fe9868-b904-4219-802a-aeef544b7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380\n",
      "['apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L', 'apple_fuji_L']\n"
     ]
    }
   ],
   "source": [
    "k = sorted(labelling)\n",
    "print(len(k))\n",
    "print(k[0:21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7515e657-507d-4211-a7f8-a459cb385d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_fuji_L', 'apple_fuji_M', 'apple_fuji_S', 'apple_yanggwang_L', 'apple_yanggwang_M', 'apple_yanggwang_S', 'cabbage_green_L', 'cabbage_green_M', 'cabbage_green_S', 'cabbage_red_L', 'cabbage_red_M', 'cabbage_red_S', 'chinese-cabbage_L', 'chinese-cabbage_M', 'chinese-cabbage_S', 'garlic_uiseong_L', 'garlic_uiseong_M', 'garlic_uiseong_S', 'mandarin_hallabong_L', 'mandarine_hallabong_M', 'mandarine_hallabong_S', 'mandarine_onjumilgam_L', 'mandarine_onjumilgam_M', 'mandarine_onjumilgam_S', 'onion_red_L', 'onion_red_M', 'onion_red_S', 'onion_white_L', 'onion_white_M', 'onion_white_S', 'pear_chuhwang_L', 'pear_chuhwang_M', 'pear_chuhwang_S', 'pear_singo_L', 'pear_singo_M', 'pear_singo_S', 'persimmon_bansi_L', 'persimmon_bansi_M', 'persimmon_bansi_S', 'persimmon_booyu_L', 'persimmon_booyu_M', 'persimmon_booyu_S', 'persimmon_daebong_L', 'persimmon_daebong_M', 'persimmon_daebong_S', 'potato_seolbong_L', 'potato_seolbong_M', 'potato_seolbong_S', 'potato_sumi_L', 'potato_sumi_M', 'potato_sumi_S', 'radish_winter-radish_L', 'radish_winter-radish_S', 'radish_winter-radish_m']\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "l = sorted(set(labelling))\n",
    "print(l)\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2f5042-2352-4ab6-a12c-44901baf96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = np.array(labelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b10820-83a6-4df6-97ac-3da47bcbf647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'fuji', 'l']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "text_to_word_sequence(labelling[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d51348-164a-4c6b-81a9-110df962b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "973679d2-728c-44db-9e5f-dce5001b4314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53}\n",
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(2380, 54)\n"
     ]
    }
   ],
   "source": [
    "# 레이블 인코딩\n",
    "items = labelling\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labelling = encoder.transform(items)\n",
    "\n",
    "\n",
    "# 원핫 인코딩\n",
    "labels = encoder.inverse_transform(labelling)\n",
    "labels = labels.reshape(-1,1)\n",
    "o_h_encoder = OneHotEncoder()\n",
    "o_h_encoder.fit(labels)\n",
    "o_h_labels = o_h_encoder.transform(labels)\n",
    "\n",
    "print(set(labelling))\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(o_h_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(o_h_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d07b9960-76e7-4345-857d-9d1e43f07fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(o_h_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03d64466-b1e2-4257-aaf2-3a629e6386ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "arr = o_h_labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82e57ad2-36e4-4def-b32d-0a808aeadefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 54)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e9750e-2fff-42b0-9423-366bb9be986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = torch.tensor(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "635e9f97-5ae6-4a7e-b277-e73b0db831d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f70474a-7957-49a2-88c5-ddeb9d095b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n"
     ]
    }
   ],
   "source": [
    "print(arr[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "663796d7-f877-4798-ba32-ded8cbd8f51c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380\n"
     ]
    }
   ],
   "source": [
    "print(len(labelling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac9619-8245-47c8-863a-fd41ce5e7524",
   "metadata": {},
   "source": [
    "# Transferring Image_to_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce52d83b-2639-4e6e-802c-3696444af283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as pilimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "870c675c-0abf-41ff-9dd3-a797962aecff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-ad5de19d3ebd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Fetch image pixel data to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#     pix = torch.tensor(pix)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#     pix = torch.reshape(pix, (-1,))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    539\u001b[0m             )\n\u001b[0;32m    540\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_category\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Read image\n",
    "image = []\n",
    "for j in image_data:\n",
    "    \n",
    "    im = pilimg.open(j)\n",
    "\n",
    "    # Fetch image pixel data to numpy array\n",
    "    pix = np.array(im)\n",
    "#     pix = torch.tensor(pix)\n",
    "#     pix = torch.reshape(pix, (-1,))\n",
    "    pix = pix / 255\n",
    "    \n",
    "    image.append(pix)\n",
    "    # plt.imshow(pix)\n",
    "#     print(pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b6cea1-6ebd-4b1c-83d4-639e8764ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for j in image_data:\n",
    "    # Read image \n",
    "\n",
    "    image1 = Image.open(j)\n",
    "    # plt.imshow(image1)\n",
    "    # plt.show()\n",
    "    imag1_size = image1.size\n",
    "    # print(imag1_size)\n",
    "\n",
    "    # Resize image\n",
    "    image1 = image1.resize((int(imag1_size[0]*(0.064)), int(imag1_size[1]*(0.064))))\n",
    "    imag1_size = image1.size\n",
    "    # plt.imshow(image1)\n",
    "    # plt.show()\n",
    "    # print(imag1_size)\n",
    "    # Fetch image pixel data to numpy array\n",
    "    pix = np.array(image1)\n",
    "    pix = pix / 255\n",
    "    pix = pix.flatten()\n",
    "\n",
    "    image.append(pix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02c593c3-b55c-43a8-a714-f0d75bdd6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c384f5a-e019-432b-bee1-c783bdf0398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2380, 12288)\n"
     ]
    }
   ],
   "source": [
    "print(type(image))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8319210d-2490-401b-b6f6-9f13e9f91851",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape(2380,12288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c228535e-3d02-42a4-9f6f-c07137be2703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78431373 0.85490196 0.8627451  ... 0.78431373 0.83921569 0.84705882]\n"
     ]
    }
   ],
   "source": [
    "print(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac59d7-2990-44ea-aebf-8f83bbafbadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "232073c0-c34d-473a-b254-73e34c9c2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdac8c06-503f-471e-b7fc-1d738dd4d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ef49e1e-501a-44bd-bbf6-5bf1b413bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(image))\n",
    "print(type(labelling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "360e24d2-d7cc-4949-a3ee-fc96b92bb5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image, labelling, test_size = 1/7, random_state = 0)\n",
    "\n",
    "# print(X_train)\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# like zipping\n",
    "\n",
    "ds_train = TensorDataset(X_train, y_train) # container that binds learning data X and label Y. (only tensor type)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_train = DataLoader(ds_train, batch_size = 20, shuffle = True)\n",
    "loader_test = DataLoader(ds_test, batch_size = 20, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cffa6a5d-41ff-44b6-ba9f-740eeab149cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(64*64*3, 100))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2',nn.Linear(100,50))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(50,54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ac76aac-1d81-4302-b760-af0c9dc40746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef1c55-c124-40b4-bd6e-5221a9649f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62063747-9ee0-45ce-8005-d81bbeafd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for data, targets in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"epoch{}: 완료\\n\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ceb430a9-8ac7-425e-bcc0-2aad6aa7639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader_test:\n",
    "            \n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
    "            \n",
    "            \n",
    "    data_num = len(loader_test.dataset)\n",
    "    print('\\n테스트 데이터에서 예측 정확도: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100 * correct / data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6ecd9a7-f2e5-4930-ad91-c29e5d7edc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 데이터에서 예측 정확도: 11/340 (3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccc9cf76-d0e5-416d-a33b-96af8eeeebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: 완료\n",
      "\n",
      "epoch1: 완료\n",
      "\n",
      "epoch2: 완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 7/340 (2%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    train(epoch)\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
